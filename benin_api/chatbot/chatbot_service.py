"""Service de chatbot expert foncier b√©ninois
Utilise FAISS + Gemini pour r√©pondre aux questions sur le foncier
"""

import os
import pickle
import faiss
import numpy as np
from typing import List, Dict, Any
from google import genai
from django.conf import settings


class FoncierChatbotService:
    """
    Service de chatbot expert en foncier b√©ninois
    """
    
    def __init__(self):
        self.client = None
        self.model_name = None
        self.index = None
        self.documents = None
        self._initialize()
    
    def _initialize(self):
        """Initialise le mod√®le et charge les index"""
        try:
            # Initialiser Gemini avec la nouvelle API
            api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
            if not api_key:
                raise ValueError("GOOGLE_API_KEY ou GEMINI_API_KEY non trouv√©e dans les variables d'environnement")
            
            # Configurer l'API key pour le client
            os.environ["GEMINI_API_KEY"] = api_key
            self.client = genai.Client()
            self.model_name = "gemini-2.5-flash"
            
            # Charger les index FAISS et documents
            self._load_knowledge_base()
            
        except Exception as e:
            print(f"Erreur initialisation chatbot: {e}")
            raise
    
    def _load_knowledge_base(self):
        """Charge la base de connaissances FAISS"""
        try:
            # Chemin vers les fichiers d'index
            base_path = os.path.dirname(__file__)
            faiss_path = os.path.join(base_path, "index.faiss")
            pkl_path = os.path.join(base_path, "index.pkl")
            
            # Essayer de charger les fichiers d'index
            try:
                if os.path.exists(pkl_path) and os.path.getsize(pkl_path) > 100:
                    with open(pkl_path, 'rb') as f:
                        self.documents = pickle.load(f)
                    print(f"‚úÖ Documents charg√©s: {len(self.documents)} √©l√©ments")
                else:
                    raise FileNotFoundError("Fichier PKL invalide ou trop petit")
                    
                if os.path.exists(faiss_path) and os.path.getsize(faiss_path) > 100:
                    self.index = faiss.read_index(faiss_path)
                    print(f"‚úÖ Index FAISS charg√©: {self.index.ntotal} documents")
                else:
                    print("‚ö†Ô∏è Index FAISS invalide, utilisation sans recherche vectorielle")
                    self.index = None
                    
            except Exception as load_error:
                print(f"‚ö†Ô∏è Erreur chargement fichiers d'index: {load_error}")
                print("üîÑ Utilisation de la base de connaissances par d√©faut")
                self.documents = self._get_default_knowledge()
                self.index = None
                
        except Exception as e:
            print(f"Erreur chargement base de connaissances: {e}")
            self.documents = self._get_default_knowledge()
            self.index = None
    
    def _get_default_knowledge(self):
        """Retourne des connaissances par d√©faut sur le foncier b√©ninois"""
        return [
            "L'ANDF (Agence Nationale du Domaine et du Foncier) est l'institution charg√©e de la gestion fonci√®re au B√©nin, cr√©√©e par la loi 2013-01.",
            "Un titre foncier est un document officiel qui atteste de la propri√©t√© d'une parcelle de terrain au B√©nin.",
            "La plateforme eFoncier permet de r√©aliser des d√©marches fonci√®res en ligne depuis janvier 2025 dans 12 communes.",
            "Plus de 74 532 titres fonciers ont √©t√© num√©ris√©s et int√©gr√©s √† la base nationale b√©ninoise.",
            "Le programme Terra Benin vise √† cartographier 1,5 million de parcelles et enregistrer 1 million de titres fonciers.",
            "Les 14 couches g√©ospatiales incluent les parcelles cadastrales, zones inondables, aires prot√©g√©es, domaines publics, etc.",
            "Les litiges fonciers peuvent √™tre r√©solus par m√©diation locale, conciliation administrative ou proc√©dure judiciaire.",
            "Les services eFoncier incluent : demande de duplicata, mutation, √©tat descriptif, radiation d'hypoth√®que.",
            "Les Bureaux communaux du domaine et du foncier sont les structures d√©concentr√©es de l'ANDF.",
            "La formalisation fonci√®re dans certaines communes doit √™tre r√©alis√©e en ligne depuis le 1er janvier 2025."
        ]
    
    def search_relevant_documents(self, query: str, k: int = 5) -> List[str]:
        """
        Recherche les documents les plus pertinents pour une requ√™te
        """
        try:
            if self.documents and len(self.documents) > 0:
                # V√©rifier le type des documents
                if isinstance(self.documents, list) and isinstance(self.documents[0], str):
                    # Documents par d√©faut (cha√Ænes de caract√®res)
                    return self.documents[:min(k, len(self.documents))]
                else:
                    # Documents charg√©s depuis FAISS (objets complexes)
                    # Extraire le texte des documents
                    text_docs = []
                    try:
                        # Si c'est un InMemoryDocstore ou un objet similaire
                        if hasattr(self.documents, 'docstore') and hasattr(self.documents.docstore, '_dict'):
                            # Extraire les documents du docstore
                            for doc_id, doc in list(self.documents.docstore._dict.items())[:k]:
                                if hasattr(doc, 'page_content'):
                                    text_docs.append(doc.page_content)
                                elif hasattr(doc, 'content'):
                                    text_docs.append(doc.content)
                                else:
                                    text_docs.append(str(doc))
                        elif hasattr(self.documents, '_dict'):
                            # Docstore direct
                            for doc_id, doc in list(self.documents._dict.items())[:k]:
                                if hasattr(doc, 'page_content'):
                                    text_docs.append(doc.page_content)
                                elif hasattr(doc, 'content'):
                                    text_docs.append(doc.content)
                                else:
                                    text_docs.append(str(doc))
                        else:
                            # Fallback: utiliser la base par d√©faut
                            return self._get_default_knowledge()[:k]
                    except Exception as extract_error:
                        print(f"Erreur extraction documents: {extract_error}")
                        return self._get_default_knowledge()[:k]
                    
                    return text_docs if text_docs else self._get_default_knowledge()[:k]
            
            # Fallback: base de connaissances par d√©faut
            return self._get_default_knowledge()[:k]
            
        except Exception as e:
            print(f"Erreur recherche documents: {e}")
            return self._get_default_knowledge()[:k]
    
    def generate_response(self, question: str, context_docs: List[str] = None) -> Dict[str, Any]:
        """
        G√©n√®re une r√©ponse experte bas√©e sur la question et le contexte
        """
        try:
            # Pr√©parer le contexte
            context = ""
            if context_docs:
                context = " ".join(context_docs[:3])  # Limiter le contexte
            
            # Prompt syst√®me sp√©cialis√© foncier b√©ninois
            system_prompt = """Tu es un expert juridique et technique en foncier b√©ninois avec 20 ans d'exp√©rience.

EXPERTISE :
- Code foncier et domanial du B√©nin
- Proc√©dures d'immatriculation et de morcellement  
- Gestion des litiges fonciers
- Analyse g√©ospatiale des parcelles
- R√©glementation ANDF (Agence Nationale du Domaine et du Foncier)
- Plateforme eFoncier et services num√©riques

STYLE DE R√âPONSE OBLIGATOIRE :
- R√©ponse en un seul paragraphe fluide et continu
- PAS de retours √† la ligne (\n) dans la r√©ponse
- PAS de formatage markdown (**, -, *, etc.)
- PAS de listes √† puces ou num√©rot√©es
- PAS d'√©mojis dans la r√©ponse
- R√©ponse claire, pr√©cise et professionnelle
- Int√©grer naturellement les informations dans un texte continu
- Maximum 200 mots

DONN√âES DISPONIBLES :
- Informations officielles ANDF
- L√©gislation fonci√®re b√©ninoise
- Proc√©dures administratives
- Services eFoncier disponibles"""

            # Construire le message
            if context:
                user_message = f"""CONTEXTE (informations officielles ANDF) : {context}

QUESTION : {question}

R√©ponds en tant qu'expert foncier b√©ninois en un seul paragraphe continu, sans retours √† la ligne, sans √©mojis, sans formatage markdown. Int√®gre naturellement toutes les informations pertinentes dans un texte fluide."""
            else:
                user_message = f"""QUESTION : {question}

R√©ponds en tant qu'expert foncier b√©ninois en un seul paragraphe continu, sans retours √† la ligne, sans √©mojis, sans formatage markdown. Maximum 200 mots."""
            
            # Construire le prompt complet
            full_prompt = f"{system_prompt}\n\n{user_message}"
            
            # G√©n√©rer la r√©ponse avec la nouvelle API
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=full_prompt
            )
            
            # Nettoyer la r√©ponse
            cleaned_answer = self._clean_response(response.text)
            
            return {
                "success": True,
                "answer": cleaned_answer,
                "context_used": len(context_docs) if context_docs else 0,
                "source": "ANDF + Expert IA"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Erreur g√©n√©ration r√©ponse: {str(e)}",
                "answer": "D√©sol√©, je ne peux pas r√©pondre √† cette question pour le moment."
            }
    
    def generate_response_stream(self, question: str, context_docs: List[str] = None):
        """
        G√©n√®re une r√©ponse experte en streaming temps r√©el (comme ChatGPT)
        """
        try:
            # Pr√©parer le contexte
            context = ""
            if context_docs:
                context = " ".join(context_docs[:3])  # Limiter le contexte
            
            # Prompt syst√®me sp√©cialis√© foncier b√©ninois
            system_prompt = """Tu es un expert juridique et technique en foncier b√©ninois avec 20 ans d'exp√©rience.

EXPERTISE :
- Code foncier et domanial du B√©nin
- Proc√©dures d'immatriculation et de morcellement  
- Gestion des litiges fonciers
- Analyse g√©ospatiale des parcelles
- R√©glementation ANDF (Agence Nationale du Domaine et du Foncier)
- Plateforme eFoncier et services num√©riques

STYLE DE R√âPONSE OBLIGATOIRE :
- R√©ponse en un seul paragraphe fluide et continu
- PAS de retours √† la ligne (\n) dans la r√©ponse
- PAS de formatage markdown (**, -, *, etc.)
- PAS de listes √† puces ou num√©rot√©es
- PAS d'√©mojis dans la r√©ponse
- R√©ponse claire, pr√©cise et professionnelle
- Int√©grer naturellement les informations dans un texte continu
- Maximum 200 mots

DONN√âES DISPONIBLES :
- Informations officielles ANDF
- L√©gislation fonci√®re b√©ninoise
- Proc√©dures administratives
- Services eFoncier disponibles"""

            # Construire le prompt complet
            if context:
                full_prompt = f"""{system_prompt}

CONTEXTE (informations officielles ANDF) : {context}

QUESTION : {question}

R√©ponds en tant qu'expert foncier b√©ninois en un seul paragraphe continu, sans retours √† la ligne, sans √©mojis, sans formatage markdown. Int√®gre naturellement toutes les informations pertinentes dans un texte fluide."""
            else:
                full_prompt = f"""{system_prompt}

QUESTION : {question}

R√©ponds en tant qu'expert foncier b√©ninois en un seul paragraphe continu, sans retours √† la ligne, sans √©mojis, sans formatage markdown. Maximum 200 mots."""
            
            # G√©n√©rer la r√©ponse (simuler le streaming)
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=full_prompt
            )
            
            # Simuler le streaming en divisant la r√©ponse
            full_text = self._clean_response(response.text)
            words = full_text.split()
            accumulated_text = ""
            
            # Simuler le streaming mot par mot
            for i, word in enumerate(words):
                accumulated_text += word + " "
                yield {
                    "type": "chunk",
                    "content": word + " ",
                    "accumulated": accumulated_text.strip(),
                    "success": True
                }
            
            # Envoyer le message de fin
            yield {
                "type": "complete",
                "final_text": accumulated_text,
                "context_used": len(context_docs) if context_docs else 0,
                "source": "ANDF + Expert IA",
                "success": True
            }
            
        except Exception as e:
            yield {
                "type": "error",
                "error": f"Erreur g√©n√©ration streaming: {str(e)}",
                "success": False
            }
    
    def generate_response_stream_with_history(self, question: str, context_docs: List[str] = None, conversation_history: List[Dict] = None):
        """
        G√©n√®re une r√©ponse experte en streaming avec historique de conversation (5 derniers messages)
        """
        try:
            # Pr√©parer le contexte
            context = ""
            if context_docs:
                context = " ".join(context_docs[:3])  # Limiter le contexte
            
            # Pr√©parer l'historique (garder les 5 derniers messages)
            history_context = ""
            if conversation_history:
                recent_history = conversation_history[-5:]  # 5 derniers messages
                history_parts = []
                for msg in recent_history:
                    role = msg.get('role', '')
                    content = msg.get('content', '')
                    if role and content:
                        if role == 'user':
                            history_parts.append(f"Utilisateur: {content}")
                        elif role == 'assistant':
                            history_parts.append(f"Expert: {content}")
                
                if history_parts:
                    history_context = " ".join(history_parts)
            
            # Prompt syst√®me sp√©cialis√© foncier b√©ninois
            system_prompt = """Tu es un expert juridique et technique en foncier b√©ninois avec 20 ans d'exp√©rience.

EXPERTISE :
- Code foncier et domanial du B√©nin
- Proc√©dures d'immatriculation et de morcellement  
- Gestion des litiges fonciers
- Analyse g√©ospatiale des parcelles
- R√©glementation ANDF (Agence Nationale du Domaine et du Foncier)
- Plateforme eFoncier et services num√©riques

STYLE DE R√âPONSE OBLIGATOIRE :
- R√©ponse en un seul paragraphe fluide et continu
- PAS de retours √† la ligne (\n) dans la r√©ponse
- PAS de formatage markdown (**, -, *, etc.)
- PAS de listes √† puces ou num√©rot√©es
- PAS d'√©mojis dans la r√©ponse
- R√©ponse claire, pr√©cise et professionnelle
- Int√©grer naturellement les informations dans un texte continu
- Tenir compte de l'historique de conversation pour donner une r√©ponse coh√©rente
- Maximum 200 mots

DONN√âES DISPONIBLES :
- Informations officielles ANDF
- L√©gislation fonci√®re b√©ninoise
- Proc√©dures administratives
- Services eFoncier disponibles"""

            # Construire le prompt complet avec historique
            prompt_parts = [system_prompt]
            
            if context:
                prompt_parts.append(f"CONTEXTE (informations officielles ANDF) : {context}")
            
            if history_context:
                prompt_parts.append(f"HISTORIQUE DE CONVERSATION : {history_context}")
            
            prompt_parts.append(f"NOUVELLE QUESTION : {question}")
            prompt_parts.append("R√©ponds en tant qu'expert foncier b√©ninois en un seul paragraphe continu, sans retours √† la ligne, sans √©mojis, sans formatage markdown. Tiens compte de l'historique de conversation pour donner une r√©ponse coh√©rente et contextuelle.")
            
            full_prompt = "\n\n".join(prompt_parts)
            
            # G√©n√©rer la r√©ponse (la nouvelle API ne supporte pas encore le streaming natif)
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=full_prompt
            )
            
            # Simuler le streaming en divisant la r√©ponse
            full_text = self._clean_response(response.text)
            words = full_text.split()
            accumulated_text = ""
            
            # Simuler le streaming mot par mot
            for i, word in enumerate(words):
                accumulated_text += word + " "
                yield {
                    "type": "chunk",
                    "content": word + " ",
                    "accumulated": accumulated_text.strip(),
                    "success": True
                }
            
            # Envoyer le message de fin
            yield {
                "type": "complete",
                "final_text": accumulated_text,
                "context_used": len(context_docs) if context_docs else 0,
                "history_used": len(conversation_history) if conversation_history else 0,
                "source": "ANDF + Expert IA",
                "success": True
            }
            
        except Exception as e:
            yield {
                "type": "error",
                "error": f"Erreur g√©n√©ration streaming avec historique: {str(e)}",
                "success": False
            }
    
    def _clean_chunk(self, chunk: str) -> str:
        """
        Nettoie un chunk de streaming en temps r√©el
        """
        if not chunk:
            return ""
        
        # Supprimer les retours √† la ligne
        cleaned = chunk.replace('\n', ' ').replace('\r', ' ')
        
        # Supprimer le formatage markdown basique
        cleaned = cleaned.replace('**', '').replace('*', '').replace('_', '')
        cleaned = cleaned.replace('###', '').replace('##', '').replace('#', '')
        
        # Supprimer les √©mojis simples (version l√©g√®re pour le streaming)
        import re
        emoji_pattern = re.compile("["
                                   u"\U0001F600-\U0001F64F"  # emoticons
                                   u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                                   u"\U0001F680-\U0001F6FF"  # transport & map symbols
                                   "]+", flags=re.UNICODE)
        cleaned = emoji_pattern.sub('', cleaned)
        
        return cleaned
    
    def _clean_response(self, response: str) -> str:
        """
        Nettoie la r√©ponse en supprimant les retours √† la ligne et le formatage
        """
        if not response:
            return ""
        
        # S'assurer que la r√©ponse est en UTF-8 propre
        if isinstance(response, bytes):
            response = response.decode('utf-8')
        
        # Supprimer tous les retours √† la ligne
        cleaned = response.replace('\n', ' ').replace('\r', ' ')
        
        # Supprimer le formatage markdown
        cleaned = cleaned.replace('**', '').replace('*', '').replace('_', '')
        cleaned = cleaned.replace('###', '').replace('##', '').replace('#', '')
        cleaned = cleaned.replace('- ', '').replace('‚Ä¢ ', '')
        
        # Supprimer les √©mojis (caract√®res Unicode d'√©mojis)
        import re
        emoji_pattern = re.compile("["
                                   u"\U0001F600-\U0001F64F"  # emoticons
                                   u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                                   u"\U0001F680-\U0001F6FF"  # transport & map symbols
                                   u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                                   u"\U00002702-\U000027B0"
                                   u"\U000024C2-\U0001F251"
                                   "]+", flags=re.UNICODE)
        cleaned = emoji_pattern.sub('', cleaned)
        
        # Nettoyer les espaces multiples
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # Supprimer les espaces en d√©but et fin
        cleaned = cleaned.strip()
        
        # S'assurer que les caract√®res sp√©ciaux fran√ßais sont corrects
        cleaned = cleaned.replace('√É¬©', '√©').replace('√É¬®', '√®').replace('√É ', '√†')
        cleaned = cleaned.replace('√É¬¥', '√¥').replace('√É¬π', '√π').replace('√É¬ß', '√ß')
        
        return cleaned
    
    def ask_question(self, question: str) -> Dict[str, Any]:
        """
        Point d'entr√©e principal pour poser une question
        """
        try:
            # Rechercher des documents pertinents
            relevant_docs = self.search_relevant_documents(question)
            
            # G√©n√©rer la r√©ponse
            response = self.generate_response(question, relevant_docs)
            
            # Ajouter des m√©tadonn√©es
            response["question"] = question
            response["timestamp"] = "now"  # Django ajoutera le timestamp
            
            return response
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Erreur traitement question: {str(e)}",
                "question": question,
                "answer": "Une erreur s'est produite. Veuillez r√©essayer."
            }


# Instance globale du service
_chatbot_service = None

def get_chatbot_service() -> FoncierChatbotService:
    """
    Retourne l'instance singleton du service chatbot
    """
    global _chatbot_service
    if _chatbot_service is None:
        _chatbot_service = FoncierChatbotService()
    return _chatbot_service
