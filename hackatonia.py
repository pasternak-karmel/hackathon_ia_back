# -*- coding: utf-8 -*-
"""HackatonIA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1--ItdTXQf6dnwaGHGkFpX2nW4juyXtS5
"""

!pip install -q langchain langchain_community langchain_huggingface faiss-cpu pypdf langgraph langchain-ollama ollama

!curl -fsSL https://ollama.com/install.sh | sh

import subprocess

# DÃ©marrer Ollama en arriÃ¨re-plan |uuuu|iiii|oooo|pppp|mmmm|
ollama_process = subprocess.Popen(["ollama", "serve"])

!ollama list

!ollama pull qwen2.5vl:7b

!ollama pull minicpm-v

!ollama pull openbmb/minicpm-o2.6

!pip install -q PyMuPDF

import os
from pathlib import Path
import fitz
from PIL import Image
import io
# from reportlab.pdfgen import canvas
# from reportlab.lib.pagesizes import A4
import ollama

# === CONFIGURATION ===
INPUT_FOLDER = "/content/"
OUTPUT_FOLDER = "/content/Final_pdfs"
MODEL = "qwen2.5vl:7b"

def ocr_image_ollama(img: Image.Image, model: str = MODEL) -> str:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    buf.seek(0)
    response = ollama.chat(
        model=model,
        messages=[{
            "role": "user",
            "content": """Extract all visible text from these scanned pages. Preserve the original formatting as much as possible.
                          Return only the extracted text â€” no explanations, no introductions, no surrounding phrases.
                          Avoid duplicates.
                          If you encounter tables or structured data, format them properly in a understandable structure.
                      """,

            "images": [buf.getvalue()]
        }],

    )
    return response["message"]["content"]

def check_ollama(text, model=MODEL) -> str:
    response = ollama.chat(
        model=model,
        messages=[{
            "role": "user",
            "content": f"Just remove any duplicates in the text and return the result to me. The text : {text}"
      }],

    )
    return response["message"]["content"]


# === PDF > IMAGES ===
def pdf_to_images(pdf_path: str, zoom: int = 4) -> list[Image.Image]:
    doc = fitz.open(pdf_path)
    mat = fitz.Matrix(zoom, zoom)
    images = []
    for page in doc:
        pix = page.get_pixmap(matrix=mat)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    return images



!pip install -q fitz

import os
from pathlib import Path
from PIL import Image
import io
import ollama

# === CONFIGURATION ===
INPUT_FOLDER = "/content/Images/"    # Dossier oÃ¹ se trouvent tes PNG/JPG
OUTPUT_FOLDER = "/content/Final_texts"   # Sauvegarde du texte extrait
MODEL = "qwen2.5vl:7b"                   # ModÃ¨le multimodal Ollama

os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# === OCR avec Ollama ===
def ocr_image_ollama(img: Image.Image, model: str = MODEL) -> str:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    buf.seek(0)
    response = ollama.chat(
        model=model,
        messages=[{
            "role": "user",
            "content": """Extract all visible text from this scanned image.
                          Preserve original formatting as much as possible.
                          Return only the extracted text â€” no explanations, no introductions.
                          Avoid duplicates.
                          If you encounter tables, format them clearly.
                      """,
            "images": [buf.getvalue()]
        }],
    )
    return response["message"]["content"]

# === Nettoyage avec Ollama ===
def check_ollama(text, model=MODEL) -> str:
    response = ollama.chat(
        model=model,
        messages=[{
            "role": "user",
            "content": f"Remove any duplicates in the text and return only the cleaned text:\n\n{text}"
        }],
    )
    return response["message"]["content"]

# === Pipeline principal ===
def process_images(input_folder: str = INPUT_FOLDER, output_folder: str = OUTPUT_FOLDER):
    for file in Path(input_folder).glob("*"):
        if file.suffix.lower() in [".png", ".jpg", ".jpeg"]:
            print(f"ðŸ“„ Processing {file.name} ...")
            img = Image.open(file)

            # OCR avec Ollama
            extracted_text = ocr_image_ollama(img)

            # Nettoyage
            cleaned_text = check_ollama(extracted_text)

            # Sauvegarde
            output_file = Path(output_folder) / (file.stem + ".txt")
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(cleaned_text)

            print(f"âœ… Done -> {output_file}")

# === Lancer le pipeline ===
if __name__ == "__main__":
    process_images()

